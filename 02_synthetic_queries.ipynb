{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "02-synthetic-queries.ipynb",
      "authorship_tag": "ABX9TyN3knbr10r7MoGhyS4bOaQn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ade8783162844d75a13f21ffed649764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60fb43ff2037454e987024d4ad0ec9c7",
              "IPY_MODEL_659bae86ab824f899bfe7fc9fd323ea0",
              "IPY_MODEL_640fc2675a5948d2b64018ecd38641a5"
            ],
            "layout": "IPY_MODEL_c5c14f0625214da985e5a370b387a24e"
          }
        },
        "60fb43ff2037454e987024d4ad0ec9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbf657358e014080bf9bfd1483ae678c",
            "placeholder": "​",
            "style": "IPY_MODEL_e7fc981441f64b1ab975b61551184be0",
            "value": "Evaluating chunks: 100%"
          }
        },
        "659bae86ab824f899bfe7fc9fd323ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_042c432c46044354a00cf07808eaf94c",
            "max": 220,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30f96846c9344a8993b4a71e6383c137",
            "value": 220
          }
        },
        "640fc2675a5948d2b64018ecd38641a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_846615190b6e40eca501357caff21781",
            "placeholder": "​",
            "style": "IPY_MODEL_6bde91939eec45bf92b876d23aa8c282",
            "value": " 220/220 [04:50&lt;00:00,  1.36s/it]"
          }
        },
        "c5c14f0625214da985e5a370b387a24e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbf657358e014080bf9bfd1483ae678c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7fc981441f64b1ab975b61551184be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "042c432c46044354a00cf07808eaf94c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f96846c9344a8993b4a71e6383c137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "846615190b6e40eca501357caff21781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bde91939eec45bf92b876d23aa8c282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wesslen/rag-workflow/blob/main/02_synthetic_queries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iJM_lk08LrzA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!uv pip install --system llama-index llama-index-embeddings-huggingface llama-index-llms-openai-like # llama-index-embeddings-instructor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "API_KEY = userdata.get('API_KEY')\n",
        "BASE_URL = userdata.get('BASE_URL')"
      ],
      "metadata": {
        "id": "6ZtqjwSULyLu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take WF Code of Conduct\n",
        "!wget -O text.txt https://r.jina.ai/https://www.wellsfargo.com/assets/pdf/about/corporate/code-of-conduct.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuIGkYiLRJnJ",
        "outputId": "f009932d-1793-407e-9012-aed7cc3cb375"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-11 02:43:07--  https://r.jina.ai/https://www.wellsfargo.com/assets/pdf/about/corporate/code-of-conduct.pdf\n",
            "Resolving r.jina.ai (r.jina.ai)... 172.67.70.54, 104.26.11.242, 104.26.10.242, ...\n",
            "Connecting to r.jina.ai (r.jina.ai)|172.67.70.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41541 (41K) [text/plain]\n",
            "Saving to: ‘text.txt’\n",
            "\n",
            "text.txt            100%[===================>]  40.57K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-01-11 02:43:08 (3.67 MB/s) - ‘text.txt’ saved [41541/41541]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "from dataclasses import dataclass\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import time\n",
        "import json\n",
        "import tiktoken\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
        "import traceback\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from openai import OpenAI\n",
        "\n",
        "from llama_index.core import VectorStoreIndex, Document, Settings\n",
        "from llama_index.llms.openai_like import OpenAILike\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from llama_index.core.evaluation import QueryResponseEvaluator\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    stream=sys.stdout\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class EvalConfig:\n",
        "    \"\"\"Configuration for the evaluation process.\"\"\"\n",
        "    # File and model paths\n",
        "    input_file: str\n",
        "    model_path: str\n",
        "    embed_model_name: str = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        "    # API settings\n",
        "    api_base: str = BASE_URL\n",
        "    api_key: str = API_KEY\n",
        "\n",
        "    # Chunking settings\n",
        "    chunk_size: int = 50\n",
        "    chunk_overlap: int = 20\n",
        "\n",
        "    # Query generation settings\n",
        "    query_temperature: float = 0.2\n",
        "    queries_per_chunk: int = 1\n",
        "\n",
        "    # LLM settings\n",
        "    max_input_tokens: int = 1152  # Default for a smaller model\n",
        "    token_buffer: int = 100  # Conservative buffer\n",
        "\n",
        "    # Evaluation settings\n",
        "    top_k: int = 5\n",
        "    batch_size: int = 10\n",
        "\n",
        "    # Debug settings\n",
        "    debug: bool = True\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Validate configuration after initialization.\"\"\"\n",
        "        if self.max_input_tokens <= self.token_buffer:\n",
        "            raise ValueError(\"max_input_tokens must be greater than token_buffer\")\n",
        "        if self.queries_per_chunk < 1:\n",
        "            raise ValueError(\"queries_per_chunk must be at least 1\")\n",
        "\n",
        "class ProcessingError(Exception):\n",
        "    \"\"\"Custom error for processing failures.\"\"\"\n",
        "    pass\n",
        "\n",
        "class RetrievalEvaluator:\n",
        "    def __init__(self, config: EvalConfig):\n",
        "        self.config = config\n",
        "        self.stats = {\n",
        "            'skipped_chunks': 0,\n",
        "            'processed_chunks': 0,\n",
        "            'failed_queries': 0,\n",
        "            'successful_queries': 0,\n",
        "            'errors': [],\n",
        "            'token_stats': {\n",
        "                'max_seen': 0,\n",
        "                'average': 0,\n",
        "                'total_tokens': 0\n",
        "            }\n",
        "        }\n",
        "        self.setup_components()\n",
        "\n",
        "    def setup_components(self):\n",
        "        \"\"\"Initialize all necessary components with robust error checking.\"\"\"\n",
        "        try:\n",
        "            # Setup encoding for token counting\n",
        "            self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "            # Calculate effective token limits\n",
        "            self.effective_max_tokens = int(self.config.max_input_tokens * 0.8)  # 20% safety margin\n",
        "\n",
        "            # Setup base prompt template\n",
        "            self.system_prompt = \"\"\"You are an assistant helping to evaluate an information retrieval system by generating realistic search queries.\n",
        "            For each text chunk provided, generate a specific query (under 10 words) that would be used to retrieve that chunk from a larger document.\n",
        "            Make the query specific enough to target the chunk's key information but natural sounding, as if a Wells Fargo employee was searching the Employee Code of Conduct.\n",
        "            Only output the query itself - no other text, explanation or commentary.\n",
        "            The query should directly relate to the main topic or requirement discussed in the chunk.\n",
        "            Do not include double quotes.\n",
        "            \"\"\"\n",
        "\n",
        "            self.user_prompt_template = \"\"\"Text chunk: {chunk}\n",
        "\n",
        "            Query: \"\"\"\n",
        "\n",
        "            # Calculate and validate base prompt tokens\n",
        "            self.base_prompt_tokens = self.count_tokens(self.system_prompt) + self.count_tokens(self.user_prompt_template)\n",
        "            self.validate_prompt_template()\n",
        "\n",
        "            # Setup components\n",
        "            self.embed_model = HuggingFaceEmbedding(\n",
        "                model_name=self.config.embed_model_name\n",
        "            )\n",
        "\n",
        "            self.client = OpenAI(\n",
        "                base_url=self.config.api_base,\n",
        "                api_key=self.config.api_key\n",
        "            )\n",
        "\n",
        "            self.node_parser = SimpleNodeParser.from_defaults(\n",
        "                chunk_size=self.config.chunk_size,\n",
        "                chunk_overlap=self.config.chunk_overlap\n",
        "            )\n",
        "\n",
        "            # Configure global settings\n",
        "            # Settings.llm = self.llm\n",
        "            Settings.embed_model = self.embed_model\n",
        "            Settings.node_parser = self.node_parser\n",
        "\n",
        "            logger.info(f\"\"\"\n",
        "            Initialization complete:\n",
        "            - Base prompt tokens: {self.base_prompt_tokens}\n",
        "            - Effective max tokens: {self.effective_max_tokens}\n",
        "            - Available tokens for content: {self.effective_max_tokens - self.base_prompt_tokens - self.config.token_buffer}\n",
        "            \"\"\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize components: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def validate_prompt_template(self):\n",
        "        \"\"\"Validate that the prompt template isn't too large.\"\"\"\n",
        "        # Count tokens for both prompts\n",
        "        system_tokens = self.count_tokens(self.system_prompt)\n",
        "        user_tokens = self.count_tokens(self.user_prompt_template)\n",
        "        total_tokens = system_tokens + user_tokens\n",
        "\n",
        "        if total_tokens > self.effective_max_tokens * 0.3:\n",
        "            raise ValueError(f\"Combined prompts too large: {total_tokens} tokens\")\n",
        "\n",
        "    def count_tokens(self, text: str) -> int:\n",
        "        \"\"\"Count tokens in text using tiktoken.\"\"\"\n",
        "        try:\n",
        "            return len(self.tokenizer.encode(text))\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Token counting failed: {str(e)}\")\n",
        "            self.track_error(\"token_count_error\", {\"text_length\": len(text), \"error\": str(e)})\n",
        "            return float('inf')  # Conservative approach - treat as too long\n",
        "\n",
        "    def track_error(self, error_type: str, details: Dict[str, Any]):\n",
        "        \"\"\"Track detailed error information.\"\"\"\n",
        "        error_info = {\n",
        "            'type': error_type,\n",
        "            'timestamp': time.time(),\n",
        "            'details': details,\n",
        "            'traceback': traceback.format_exc()\n",
        "        }\n",
        "        self.stats['errors'].append(error_info)\n",
        "\n",
        "    def debug_token_counts(self, chunk: str):\n",
        "        \"\"\"Debug token counting for a chunk.\"\"\"\n",
        "        if self.config.debug:\n",
        "            prompt = self.user_prompt_template.format(chunk=chunk)\n",
        "            logger.debug(f\"\"\"\n",
        "                Debug token counts:\n",
        "                - System prompt: {self.count_tokens(self.system_prompt)}\n",
        "                - User prompt template: {self.count_tokens(self.user_prompt_template)}\n",
        "                - Chunk: {self.count_tokens(chunk)}\n",
        "                - Full user prompt: {self.count_tokens(prompt)}\n",
        "                - Buffer: {self.config.token_buffer}\n",
        "                - Max allowed: {self.effective_max_tokens}\n",
        "            \"\"\")\n",
        "\n",
        "    def is_chunk_processable(self, chunk: str) -> bool:\n",
        "        \"\"\"Check if chunk can be processed within token limits.\"\"\"\n",
        "        chunk_tokens = self.count_tokens(chunk)\n",
        "        total_tokens = self.base_prompt_tokens + chunk_tokens\n",
        "\n",
        "        # Update token statistics\n",
        "        self.stats['token_stats']['max_seen'] = max(\n",
        "            self.stats['token_stats']['max_seen'],\n",
        "            total_tokens\n",
        "        )\n",
        "        self.stats['token_stats']['total_tokens'] += total_tokens\n",
        "\n",
        "        # Add extra buffer for message formatting\n",
        "        estimated_total = total_tokens + self.config.token_buffer\n",
        "\n",
        "        is_processable = estimated_total <= self.effective_max_tokens\n",
        "\n",
        "        if not is_processable:\n",
        "            logger.info(f\"\"\"\n",
        "                Chunk exceeds token limits:\n",
        "                - Chunk tokens: {chunk_tokens}\n",
        "                - Base prompt tokens: {self.base_prompt_tokens}\n",
        "                - Estimated total: {estimated_total}\n",
        "                - Limit: {self.effective_max_tokens}\n",
        "                - First 100 chars: {chunk[:100]}...\n",
        "            \"\"\")\n",
        "\n",
        "        return is_processable\n",
        "\n",
        "    def process_large_chunk(self, chunk: str) -> List[str]:\n",
        "        \"\"\"Handle chunks that are too large by taking a subset.\"\"\"\n",
        "        if not self.is_chunk_processable(chunk):\n",
        "            # Take first N tokens that fit within limits\n",
        "            tokens = self.tokenizer.encode(chunk)\n",
        "            safe_token_limit = self.effective_max_tokens - self.base_prompt_tokens - self.config.token_buffer\n",
        "            truncated_tokens = tokens[:safe_token_limit]\n",
        "            truncated_chunk = self.tokenizer.decode(truncated_tokens)\n",
        "\n",
        "            logger.info(f\"Truncated chunk from {len(tokens)} to {len(truncated_tokens)} tokens\")\n",
        "\n",
        "            return self.generate_queries(truncated_chunk)\n",
        "        return self.generate_queries(chunk)\n",
        "\n",
        "    @retry(\n",
        "        stop=stop_after_attempt(3),\n",
        "        wait=wait_exponential(multiplier=1, min=4, max=10),\n",
        "        retry=retry_if_exception_type(Exception)\n",
        "    )\n",
        "    def generate_query_with_retry(self, chunk: str) -> Optional[str]:\n",
        "        \"\"\"Generate a query with retry logic.\"\"\"\n",
        "        try:\n",
        "            if not self.is_chunk_processable(chunk):\n",
        "                return None\n",
        "\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.config.model_path,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": self.system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": self.user_prompt_template.format(chunk=chunk)}\n",
        "                ],\n",
        "                temperature=self.config.query_temperature\n",
        "            )\n",
        "            self.stats['successful_queries'] += 1\n",
        "            return response.choices[0].message.content.strip()\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Failed to generate query: {str(e)}\")\n",
        "            self.stats['failed_queries'] += 1\n",
        "            self.track_error(\"query_generation_error\", {\n",
        "                \"chunk_length\": len(chunk),\n",
        "                \"error\": str(e)\n",
        "            })\n",
        "            return None\n",
        "\n",
        "    def generate_queries(self, chunk: str) -> List[str]:\n",
        "        \"\"\"Generate queries for a given chunk.\"\"\"\n",
        "        self.debug_token_counts(chunk)\n",
        "\n",
        "        if not self.is_chunk_processable(chunk):\n",
        "            self.stats['skipped_chunks'] += 1\n",
        "            logger.warning(f\"\"\"\n",
        "                Skipping chunk due to length:\n",
        "                - Characters: {len(chunk)}\n",
        "                - Tokens: {self.count_tokens(chunk)}\n",
        "            \"\"\")\n",
        "            return []\n",
        "\n",
        "        self.stats['processed_chunks'] += 1\n",
        "        queries = []\n",
        "        for _ in range(self.config.queries_per_chunk):\n",
        "            query = self.generate_query_with_retry(chunk)\n",
        "            if query:\n",
        "                queries.append(query)\n",
        "\n",
        "        return queries\n",
        "\n",
        "    def load_and_index_document(self) -> Tuple[VectorStoreIndex, List[Document]]:\n",
        "        \"\"\"Load document and create index.\"\"\"\n",
        "        logger.info(\"Loading and indexing document...\")\n",
        "\n",
        "        try:\n",
        "            with open(self.config.input_file, 'r') as f:\n",
        "                text = f.read()\n",
        "\n",
        "            documents = [Document(text=text)]\n",
        "            nodes = self.node_parser.get_nodes_from_documents(documents)\n",
        "\n",
        "            # Create index with local settings\n",
        "            index = VectorStoreIndex.from_documents(\n",
        "                documents,\n",
        "                embed_model=self.embed_model,\n",
        "                transformations=[self.node_parser]\n",
        "            )\n",
        "\n",
        "            return index, nodes\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to load and index document: {str(e)}\")\n",
        "            self.track_error(\"indexing_error\", {\"error\": str(e)})\n",
        "            raise\n",
        "\n",
        "    def evaluate_retrieval(self, index: VectorStoreIndex, nodes: List[Document]) -> Dict:\n",
        "        \"\"\"Evaluate retrieval performance.\"\"\"\n",
        "        logger.info(\"Starting retrieval evaluation...\")\n",
        "\n",
        "        query_engine = index.as_query_engine(\n",
        "            llm=None,\n",
        "            similarity_top_k=self.config.top_k\n",
        "        )\n",
        "\n",
        "        results = {\n",
        "            'hit_at_k': [],\n",
        "            'queries': [],\n",
        "            'original_chunks': [],\n",
        "            'retrieval_times': [],\n",
        "            'skipped_chunks': [],\n",
        "            'stats': self.stats\n",
        "        }\n",
        "\n",
        "        for node in tqdm(nodes, desc=\"Evaluating chunks\"):\n",
        "            # Try to process the chunk, potentially with truncation\n",
        "            queries = self.process_large_chunk(node.text)\n",
        "\n",
        "            if not queries:\n",
        "                results['skipped_chunks'].append({\n",
        "                    'chunk': node.text[:200] + \"...\",  # Only store preview\n",
        "                    'reason': 'Token limit exceeded or query generation failed',\n",
        "                    'token_count': self.count_tokens(node.text)\n",
        "                })\n",
        "                continue\n",
        "\n",
        "            for query in queries:\n",
        "                try:\n",
        "                    start_time = time.time()\n",
        "                    response = query_engine.query(query)\n",
        "                    retrieval_time = time.time() - start_time\n",
        "\n",
        "                    retrieved_texts = [n.node.text for n in response.source_nodes]\n",
        "                    is_found = node.text in retrieved_texts\n",
        "\n",
        "                    results['hit_at_k'].append(int(is_found))\n",
        "                    results['queries'].append(query)\n",
        "                    results['original_chunks'].append(node.text)\n",
        "                    results['retrieval_times'].append(retrieval_time)\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error during retrieval: {str(e)}\")\n",
        "                    self.track_error(\"retrieval_error\", {\n",
        "                        \"query\": query,\n",
        "                        \"error\": str(e)\n",
        "                    })\n",
        "\n",
        "        # Update average token stats\n",
        "        if self.stats['processed_chunks'] > 0:\n",
        "            self.stats['token_stats']['average'] = (\n",
        "                self.stats['token_stats']['total_tokens'] /\n",
        "                self.stats['processed_chunks']\n",
        "            )\n",
        "\n",
        "        return results\n",
        "\n",
        "    def visualize_results(self, results: Dict):\n",
        "        \"\"\"Create visualizations of the evaluation results.\"\"\"\n",
        "        if not results['hit_at_k']:\n",
        "            logger.warning(\"No results to visualize - all chunks may have been skipped\")\n",
        "            return\n",
        "\n",
        "        hit = np.mean(results['hit_at_k'])\n",
        "        avg_time = np.mean(results['retrieval_times'])\n",
        "\n",
        "        print(\"\\nEvaluation Statistics:\")\n",
        "        print(f\"Overall Hit@{self.config.top_k}: {hit:.3f}\")\n",
        "        print(f\"Average retrieval time: {avg_time:.3f} seconds\")\n",
        "\n",
        "        print(f\"\\nProcessing Statistics:\")\n",
        "        print(f\"Processed chunks: {self.stats['processed_chunks']}\")\n",
        "        print(f\"Skipped chunks: {self.stats['skipped_chunks']}\")\n",
        "        print(f\"Successful queries: {self.stats['successful_queries']}\")\n",
        "        print(f\"Failed queries: {self.stats['failed_queries']}\")\n",
        "\n",
        "        print(f\"\\nToken Statistics:\")\n",
        "        print(f\"Max tokens seen: {self.stats['token_stats']['max_seen']}\")\n",
        "        print(f\"Average tokens: {self.stats['token_stats']['average']:.1f}\")\n",
        "\n",
        "        if self.stats['errors']:\n",
        "            print(f\"\\nEncountered {len(self.stats['errors'])} errors\")\n",
        "\n",
        "        # Plot timing distribution\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.hist(results['retrieval_times'], bins=30)\n",
        "        plt.title('Distribution of Retrieval Times')\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Count')\n",
        "        plt.show()\n",
        "\n",
        "    def run_evaluation(self):\n",
        "        \"\"\"Run the complete evaluation pipeline.\"\"\"\n",
        "        # Load and index document\n",
        "        index, nodes = self.load_and_index_document()\n",
        "\n",
        "        # Run evaluation\n",
        "        results = self.evaluate_retrieval(index, nodes)\n",
        "\n",
        "        # Visualize results\n",
        "        self.visualize_results(results)\n",
        "\n",
        "        # Save results\n",
        "        output_path = Path(self.config.input_file).with_suffix('.eval_results.json')\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(results, f)\n",
        "\n",
        "        return results\n",
        "\n"
      ],
      "metadata": {
        "id": "3viLELyIimSd"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = EvalConfig(\n",
        "    input_file=\"text.txt\",\n",
        "    model_path=\"/models/NousResearch/Meta-Llama-3.1-8B-Instruct\",\n",
        "    max_input_tokens=1000  # Set based on your model's context window\n",
        ")\n",
        "\n",
        "evaluator = RetrievalEvaluator(config)\n",
        "results = evaluator.run_evaluation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762,
          "referenced_widgets": [
            "ade8783162844d75a13f21ffed649764",
            "60fb43ff2037454e987024d4ad0ec9c7",
            "659bae86ab824f899bfe7fc9fd323ea0",
            "640fc2675a5948d2b64018ecd38641a5",
            "c5c14f0625214da985e5a370b387a24e",
            "cbf657358e014080bf9bfd1483ae678c",
            "e7fc981441f64b1ab975b61551184be0",
            "042c432c46044354a00cf07808eaf94c",
            "30f96846c9344a8993b4a71e6383c137",
            "846615190b6e40eca501357caff21781",
            "6bde91939eec45bf92b876d23aa8c282"
          ]
        },
        "id": "0hcThQpMiyQe",
        "outputId": "6273d2b7-17a6-419e-b491-0698e90ccb02"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating chunks:   0%|          | 0/220 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ade8783162844d75a13f21ffed649764"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Statistics:\n",
            "Overall Hit@5: 0.791\n",
            "Average retrieval time: 0.845 seconds\n",
            "\n",
            "Processing Statistics:\n",
            "Processed chunks: 220\n",
            "Skipped chunks: 0\n",
            "Successful queries: 220\n",
            "Failed queries: 0\n",
            "\n",
            "Token Statistics:\n",
            "Max tokens seen: 191\n",
            "Average tokens: 505.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def process_json_to_csvs(json_data, output_dir='output'):\n",
        "    \"\"\"\n",
        "    Process JSON data and create multiple CSV files for different components.\n",
        "    Now includes original chunks and ranking information in hit_queries.csv.\n",
        "\n",
        "    Parameters:\n",
        "    json_data (dict): Parsed JSON data\n",
        "    output_dir (str): Directory to save CSV files\n",
        "    \"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # 1. Create hit_queries.csv with enhanced information\n",
        "    hit_data = pd.DataFrame({\n",
        "        'query': json_data['queries'],\n",
        "        'original_chunk': json_data['original_chunks'],\n",
        "        'hit_score': json_data['hit_at_k'],\n",
        "        'original_chunk_found': [bool(score) for score in json_data['hit_at_k']],\n",
        "        'rank': ['1' if score == 1 else 'Not in top k' if score == 0 else 'Unknown'\n",
        "                for score in json_data['hit_at_k']],\n",
        "        'retrieval_time': json_data['retrieval_times']\n",
        "    })\n",
        "    hit_data.to_csv(f'{output_dir}/hit_queries.csv', index=False)\n",
        "\n",
        "    # 2. Create original_chunks.csv\n",
        "    chunks_data = pd.DataFrame({\n",
        "        'chunk_id': range(len(json_data['original_chunks'])),\n",
        "        'content': json_data['original_chunks']\n",
        "    })\n",
        "    chunks_data.to_csv(f'{output_dir}/original_chunks.csv', index=False)\n",
        "\n",
        "    # 3. Create retrieval_times.csv\n",
        "    retrieval_data = pd.DataFrame({\n",
        "        'chunk_id': range(len(json_data['retrieval_times'])),\n",
        "        'retrieval_time': json_data['retrieval_times']\n",
        "    })\n",
        "    retrieval_data.to_csv(f'{output_dir}/retrieval_times.csv', index=False)\n",
        "\n",
        "    # 4. Create stats.csv - flattening the stats dictionary\n",
        "    stats_dict = json_data['stats']\n",
        "    # Handle nested token_stats\n",
        "    token_stats = stats_dict.pop('token_stats')\n",
        "    stats_dict.update({f'token_{k}': v for k, v in token_stats.items()})\n",
        "    # Convert errors list to string to store in CSV\n",
        "    stats_dict['errors'] = ','.join(map(str, stats_dict['errors']))\n",
        "\n",
        "    stats_df = pd.DataFrame([stats_dict])\n",
        "    stats_df.to_csv(f'{output_dir}/stats.csv', index=False)\n",
        "\n",
        "    # Print summary statistics\n",
        "    print(\"\\nSummary Statistics:\")\n",
        "    print(f\"Total queries processed: {len(hit_data)}\")\n",
        "    print(f\"Queries where original chunk was found: {sum(hit_data['original_chunk_found'])}\")\n",
        "    print(f\"Average retrieval time: {hit_data['retrieval_time'].mean():.3f} seconds\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to read JSON from file and process it.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read the JSON data from the file\n",
        "        with open('text.eval_results.json', 'r', encoding='utf-8') as file:\n",
        "            json_data = json.load(file)\n",
        "\n",
        "        # Process the JSON data and create CSV files\n",
        "        process_json_to_csvs(json_data)\n",
        "\n",
        "        print(\"\\nCSV files have been created successfully in the 'output' directory:\")\n",
        "        print(\"1. hit_queries.csv - Contains queries, original chunks, and retrieval metrics\")\n",
        "        print(\"2. original_chunks.csv - Contains the original text chunks\")\n",
        "        print(\"3. retrieval_times.csv - Contains retrieval times for each chunk\")\n",
        "        print(\"4. stats.csv - Contains processing statistics\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: text.eval_results.json file not found\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error: Invalid JSON format in the input file\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ctEWM-NtoMu",
        "outputId": "d14e0999-6179-4096-dfb4-c038a79c5966"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary Statistics:\n",
            "Total queries processed: 220\n",
            "Queries where original chunk was found: 174\n",
            "Average retrieval time: 0.845 seconds\n",
            "\n",
            "CSV files have been created successfully in the 'output' directory:\n",
            "1. hit_queries.csv - Contains queries, original chunks, and retrieval metrics\n",
            "2. original_chunks.csv - Contains the original text chunks\n",
            "3. retrieval_times.csv - Contains retrieval times for each chunk\n",
            "4. stats.csv - Contains processing statistics\n"
          ]
        }
      ]
    }
  ]
}